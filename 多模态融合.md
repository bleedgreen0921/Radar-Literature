# 多模态融合

## 多传感器标定

精确的传感器校准是自动驾驶汽车多传感器感知和定位系统的先决条件。

传感器的**内参校准是为获得传感器内部的映射关系**，**外参校准是将两个或多个传感器转换为统一的空间坐标系**。

融合多个异构传感器成为提升鲁棒性和准确感知和定位能力的关键。

IMU（惯性测量单元）、GNSS（全球导航卫星系统）、LiDAR（光探测和测距）、相机、毫米波雷达和车轮速度计是自动驾驶系统最常用的传感器。

GNSS可以为车辆提供具有米级精度的绝对定位。然而，GNSS信号的质量不能始终保证。因此，在自动驾驶领域，GNSS的输出通常与IMU和汽车的传感器（如车轮速度计、方向盘角度传感器等）融合。

相机具有提取环境详细信息的强大能力。除了颜色，它还可以提供纹理和对比度数据——可靠地识别道路标记或交通标志，准确检测和识别静止和移动的物体。因此，无论使用哪种传感器方案，通常都会使用相机。尽管有这么多优势，但摄像头无法在自动驾驶感知系统中“领先”。这不仅是因为它需要良好的照明环境。相机在雪、雾和黑暗等恶劣环境条件下的可靠性有限。这也是因为它获得的数据或图像是二维的，没有直接的深度值信息。

激光雷达具有精度高、测距远、实时性好、信息采集丰富等突出优势。同时，它具有更好的环境适应性，不受光线影响。然而，激光雷达的成本相对较高。另一个问题是，它缺乏颜色信息，并且不够准确，无法检测到可以产生反射或透明度的物体。收集的数据需要极高的计算能力，扫描速度相对较慢。

毫米波雷达也是一类技术相对成熟的环境传感器。由于其大规模生产，雷达相对便宜，对周围车辆的检测精度高，对某些材料敏感。同时，它反应迅速，易于操作，能够适应恶劣天气。然而，雷达的分辨率相对较低。它无法判断被识别物体的大小，也无法感知行人。它无法准确模拟周围的所有障碍物。

由于单个传感器的优缺点，多传感器融合系统的目的是提高信息冗余度和信息互补性，从而充分保证自动驾驶的安全性。

传感器校准可分为两部分：内在参数校准和外在参数校准。

内在参数决定了传感器的内部映射关系。例如，相机的固有参数是通过焦距和镜头畸变来校准的。IMU的固有参数通过陀螺仪和加速度计的零偏、比例因子和安装误差进行校准。LiDAR固有参数是内部激光发射器坐标与LiDAR坐标设备之间的转换关系。

外部参数决定了传感器和外部坐标系之间的转换关系，包括旋转和平移的6个自由度参数。

------

### 基于目标的方法（Target-based Method）

基于目标的校准方法在传感器校准过程中得到了广泛的应用。基于目标的方法通常需要手动校准目标，如棋盘、多边形板，这两种传感器模式都可以很容易地检测到。

此外，基于目标的方法可以使用关于目标的先验知识，从而增强校准结果。目标方法比无目标方法更精确。传感器的固有校准通常采用目标法。

常用的相机固有校准方法是使用棋盘的方法。除了棋盘图案，还有一个常见的圆圈网格来校准相机的固有特性。一些激光雷达固有校准方法是通过盒子或平面墙进行的。多个传感器之间的外部校准通常通过基于目标的方法进行，如工厂校准、校准室。

### 无目标的方法（Target-less Method）

在某些情况下，基于目标的方法不切实际，导致了无目标方法的发展。无目标方法比目标更方便，因为不需要特定的目标。这些方法使用**环境特征**来匹配传感器数据中的对应关系。

### 基于运动的方法（Motion-based Method）

基于运动的方法将传感器外部校准视为手眼校准问题。这种方法不需要传感器之间的视场重叠，通常对初始值具有更好的鲁棒性，但这种方法的精度较低。只要传感器有里程表信息，问题就可以转化为求解齐次线性方程组的问题。

这个问题有不同形式的解决方案，如四元数形式、对偶四元数格式、螺旋运动和螺旋轴形式。不同形式的解对应于相同的方法，但与只能获得旋转校准的其他形式的解相比，对偶四元数形式可以额外获得平移校准。然而，这些方法没有充分考虑测量的不确定性，导致校准精度容易受到传感器噪声的影响。

时间校准也是基于运动的方法的重要组成部分。一般来说，时间校准有三种方法，包括硬件同步、双向通信的软件同步和单向通信的软件同期。我们的时间校准属于第三种方法，它通过两种方式完成，使用每个传感器的里程计数据，通过优化的解决方案获得时间校准，或通过数据相关性获得校准结果。

### 基于学习的方法（Learning-based Method）

近年来，深度学习网络在处理2D和3D计算机视觉任务（如定位、对象检测和分割）方面表现出了有效性。还有一些工作将深度学习应用于传感器校准任务，特别是适应相机和LiDAR校准问题。相比之下，针对内在校准问题的基于学习的方法要少得多。由于相机固有校准问题和高精度要求中不太直观的空间关系，基于学习的方法显示出的优势较少。除了用于传感器校准的端到端深度学习网络外，一些相关视觉任务的工作也可以作为校准过程的关键部分，如消失点检测、汽车航向预测和相机姿态估计。

尽管基于学习的方法在模型训练后无需人工干预即可更有效地利用深度学习的力量进行空间特征提取和匹配，但这些方法仅限于某些传感器的校准，特别是相机和激光雷达。与非学习方法相比，大多数基于学习的方法稳定性和精度较低，而精度在校准任务中至关重要。因此，一般来说，深度网络通常不用于多传感器校准问题。

根据信息提取方法的不同，多传感器在线标定的研究方向可分为三种方法：边缘配准、互信息和分割。

世界坐标->摄像机坐标->图像坐标->像素坐标

张正友标定法

------

## 毫米波雷达与视觉融合

------

### 毫米波雷达基本特性

**目标测量特性**：

- **测距：TOF(Time Of Flight)**

  - **目标距离估计**

    ![image-20250527160318326](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527160318326.png)

    RX和TX信号之间的时间差：𝜏 = 2𝑟/𝑐

    其中，𝑟为目标距离，𝑐表示光速𝜏 = 2𝑟/𝑐 --> **r =𝜏𝑐/2 =Δ𝑓𝑐/2𝑆**

    ∆𝑓 : 𝑆𝜏, IF信号的频率（RX和TX信号的频率差），S: 频率变化率（斜率）

    **最大探测距离**：

    - 带宽限制：**∆f<B：频率变化小于带宽**
    - **采样定理：∆f<Fs/2**，中频信号的大小取决于ADC采样频率，需要信号自身频率两倍的采样频率
    - **最大测量距离主要受限于IF的采样频率**

    **距离分辨率**：**雷达能区分两个不同目标的最小距离**

    - 傅里叶变换理论：观测时间窗口T，可以分辨间隔超过1/THz的频率分量
    -  **|∆f1-∆f2 |>1/Tc**（一个Chirp的时间Tc就是一个观测窗口）

    - 距离分辨率=**∆r>c/(2STc )=c/2B**，才能从傅里叶变换的频谱上分离出来

  - **多目标距离估计**

    ![image-20250527161904115](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527161904115.png)

    - Tx发送一个chirp，Rx接收来自多个目标的信号
    - 对IF信号进行FFT操作，产生具有不同的峰值的频谱，每个
      峰值表示在特定距离处的目标
    - **问题？当多个目标距离一致：无法通过range区分**

- ------

  **测速：Dopler原理**

  - **目标速度估计**

    - **中频信号的相位对物体范围的微小变化非常敏感**

    - 假设雷达发出两个线性调频脉冲，得到两个相应的IF信号X1和X2：

      ![image-20250527162329580](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527162329580.png)

      为了避免测量模糊性，**最大测量速度：| ΔΦ| < π 代入目标速度公式得: 𝑣 < 𝜆/4𝑇𝑐**

- **生成RDM(Range-Doppler Map)**

  ![image-20250527162800820](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527162800820.png)

  - 与啁啾(chirp)相对应的ADC数据存储为矩阵的行
  - 每行上进行Range- FFT解析范围信息
  - 沿着列进行Doppler- FFT解析每一列(Range Bin)的速度信息
  - **Q：当目标距离、速度都相同，如何辨别？A：角度信息**

  ![image-20250527162908051](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527162908051.png)

- ------

  **测角度：多根天线+阵列信号处理**

  - **目标角度估计**

    ![image-20250527163040238](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527163040238.png)

    ![image-20250527163141558](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527163141558.png)

    - 目标的方位角：**越靠近雷达FOV的边缘，角度分辨率越低**
    - 天线的个数：**角度分辨率与天线个数成正比关系**

**其他特性**：

- 沿直线传播 : 电磁波是由正交的电场和磁场相互作用而产生并以波的形式传播
- **多径干扰**：传播过程中遇到障碍物并反射、散射等产生多条路径，导致接收到的信号由多个分量组成
- 绕射：由于物体表面的不规则，导致信号的一部分绕过物体的边缘向后散射 
- 波束：发射出去的电磁波是一个**锥状的波束**，而不像激光是一条线

------

**FMCW毫米波雷达**：

- 利用高频电路产生特定调制频率（FMCW）的电磁波，并通过天线发送电磁波和接收从目标反射回来的电磁波，
  通过发送和接收电磁波的参数来计算目标的各个参数

- 波形：FMCW发送的是频率随时间变化的波形，通常是线性变化的，也称线性调频连续波(LFMCW)

- B为带宽，Tc为chirp周期，fc为起始频率，S为频率变化率

  ![image-20250527151945998](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527151945998.png)



------

### 雷达信号处理与数据格式

![image-20250527150833424](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527150833424.png)

处理流程：

- 发射天线在每一帧中都会发出M个Chirp的信号，每个Chirp的采样个数为N。同时，K个接收天线会收到K组返回信号。
- 混频器将它们与发射信号混合后得到中频信号IF，IF信号经过滤波和ADC，得到三维的ADC数据块。
- 对数据块依次进行Range FFT和Doppler FFT，得到RD数据块。
  - 对RD数据块进行峰值检测，Angle FFT和后处理，得到Target list（Point cloud），采用聚类算法和卡尔曼滤波检测并跟踪目标。
  - 对RD数据块进行Angle FFT，得到RAD数据块。

**RD**：

1. ADC数据作Range-FFT
2. Doppler-FFT，构建RD map

**RAD**：

1. ADC数据作Range-FFT
2. Doppler-FFT，构建Range-Dopper map 
3. Angle-FFT
4. 得到RAD map

**Point cloud**：

1. ADC数据作range-FFT
2. Doppler-FFT，构建Range-Dopper map 
3. **恒虚警率CFAR后处理**
4. 最后对候选点作Angle-FFT，后处理 
5. 得到target list

------

**恒虚警率CFAR后处理(Constant False-Alarm Rate)**

![image-20250527163710679](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527163710679.png)

**固定阈值：**

![image-20250527163741217](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527163741217.png)

阈值1：误检率很低，但是召回率也很低 
阈值2：召回率很高，但是误检率也很高

**动态阈值：**

![image-20250527163801063](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527163801063.png)

动态阈值：在提高召回率的同时，将误检率保持在一个较低的水平

------

### 1D CFAR与2D CFAR原理分析

![](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527170540861.png)

------

**1D CFAR（一维恒虚警率检测）**

**核心原理**

1. **单元划分**
   - 对一维信号（如雷达距离单元）定义三个区域：
     - **CUT（Cell Under Test）**：橙色方块，待检测单元
     - **保护单元**：绿色方块，紧邻CUT两侧，避免信号能量泄漏影响检测
     - **参考单元**：灰色方块，分布在保护单元外侧，用于噪声背景估计
2. **噪声背景计算**
   - 仅使用参考单元的数据计算局部噪声均值（排除保护单元干扰）
3. **阈值动态生成**
   - **阈值 = 噪声均值 × 比例因子**
   - 比例因子通过预设的虚警概率（如10^-6）计算，确保误检率恒定
4. **目标判决**
   - 若CUT值 > 阈值 → 判为目标
   - 若CUT值 ≤ 阈值 → 判为噪声

**特点**

- 适用于雷达距离维检测（如测距场景）
- 计算量低，但易受邻近强目标干扰（需保护单元隔离）

------

**2D CFAR（二维恒虚警率检测）**

**核心原理**

1. **区域扩展**
   - 将一维单元扩展为二维矩阵（如雷达距离-多普勒图）
   - 以CUT为中心构建二维保护区域和参考区域：
2. **噪声估计策略**
   - 参考单元分布在保护区域外围（如环形或矩形框）
   - 采用滑动窗口法遍历所有单元，计算参考区域均值或有序统计量（OS-CFAR）
3. **多维阈值计算**
   - 阈值 = 参考单元统计量 × 比例因子 + 修正项
   - 比例因子需考虑二维数据统计特性（如空间相关性）
4. **目标判别**
   - 二维空间内逐单元比较CUT值与阈值，标记潜在目标

**特点**

- 适用于雷达成像、SAR图像处理等二维数据场景
- 抗干扰能力更强（二维参考单元提供更全面的背景估计）
- 计算复杂度显著增加（需优化算法加速）

------

**关键对比**

| 特性           | 1D CFAR                     | 2D CFAR                        |
| -------------- | --------------------------- | ------------------------------ |
| **适用场景**   | 一维信号（如距离/速度单元） | 二维数据（如距离-多普勒/图像） |
| **抗干扰能力** | 一般（依赖保护单元隔离）    | 更强（二维参考单元空间滤波）   |
| **计算复杂度** | 低（线性复杂度）            | 高（平方复杂度）               |
| **典型应用**   | 雷达测距、通信信号检测      | SAR成像、毫米波雷达点云处理    |

------

### 4D毫米波雷达

3D毫米波雷达：

- 3D信息(x, y, v)
  ，缺乏高度信息，无法辨别同距离桥洞与前车，虚警造成误刹 
- 不能很好地识别静止物体、物体高度或者区分相邻障碍物

4D毫米波雷达：

- 测高能力：具有高度（俯仰角）信息
- 更高的分辨率
- 探测距离也能更远，最远可达到300m以上
- 输出更密集的目标点云，因此有助于引入神经网络等AI算法处理数据 
- 对静态目标检测能力

------

## 毫米波雷达基础算法

------

### 聚类算法

点云聚类算法是将空间中大量的点（如由激光雷达、毫米波雷达、立体视觉或结构光等传感器采集到的点云）按照一定的规则分组，使得每组中的点在空间上更为接近，便于后续的**目标检测、跟踪、识别或重建**等任务。

#### **K-Means系列**：

<img src="C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527172909054.png" alt="image-20250527172909054" style="zoom:50%;" />

**经典K-Means算法：**

1. 定义损失函数，数据标准化
2. **随机选取**K个聚类中心
3. 对每个点云，分配其**距离最近**的中心
4. 所有点云分配完成后，重新计算所有点云簇**各自中心作为下一轮迭代中心**，重复第三步

**K-Means++算法：**

原始算法随机选取K个中心的做法，需要迭代次数过多。

改进：在选择下一个中心时选择**最远的点**

**评价**：

1. KMeans尤其容易受到异常值的影响
2. 很难找到一个合适的K值
3.  Kmeans 算法会把所有的数据点都进行分类，一些**离群点无法剔除**
4. 主要适用于**球形分布**的数据

#### 基于密度的聚类（Density-Based）

**DBSACN（Density-Based Spatial Clustering Algorithm with Noise）**：

![image-20250527173527813](C:\Users\adminqiu\AppData\Roaming\Typora\typora-user-images\image-20250527173527813.png)

一种**基于密度**，对**噪声鲁棒**的空间聚类算法。

- **核心思想**：高密度区域中的点归为一类，稀疏区域为噪声或边界。

- **特点：**

  - 基于密度，对远离密度核心的噪声点鲁棒

  - 无需知道聚类簇的数量

  - 可以发现任意形状的聚类簇

#### 基于距离的欧几里得聚类（Euclidean Cluster Extraction）

- **核心思想**：以某点为中心，搜索 `radius` 内所有点并归为一类，递归展开。

- **优点**：实现简单，速度快。

- **缺点**：不能处理密度变化大或重叠的点云。

- **常用库**：PCL（Point Cloud Library）中 `EuclideanClusterExtraction` 算法。

- **适合应用**：规则场景下的目标分割。

#### 基于网格/体素的聚类（Voxel Grid Clustering）

- **核心思想**：先将点云划分为体素栅格（Voxel Grid），再进行聚类。

- **优点**：加快聚类速度，适合稠密点云。

- **缺点**：空间分辨率受体素大小影响。

- **应用**：高速处理海量点云。

#### 基于图的聚类（Graph-Based Clustering）

- **方法示例**：谱聚类（Spectral Clustering）、最小生成树（MST）聚类等。
- **核心思想**：构建点间图结构，通过图割等方法划分。
- **优点**：理论基础好，能处理复杂结构。
- **缺点**：计算复杂度高，不适合实时处理。

#### 基于学习的方法（Learning-Based Clustering）

- **方法示例**：PointNet、PointNet++、DGCNN 等网络中的特征学习与分割。
- **优点**：可学习上下文语义和结构信息，精度高。
- **缺点**：需要大量标注数据和训练时间。
- **应用**：自动驾驶、高精地图建模、复杂目标识别。

### 匹配算法

#### 匈牙利匹配算法

- 作用：多目标跟踪中用来解决多目标跟踪中的**数据关联**问题（前一帧的目标与当前帧的检测结果进行匹配）
- 本质：**二分图的最大匹配问题**

### 滤波算法

#### KF卡尔曼滤波

卡尔曼滤波（Kalman filter）是一种利用**线性系统**状态方程，通过系统输入输出观测数据，对系统状态进行**最优估计**的算法。

https://space.bilibili.com/230105574/lists/1814741?type=season

#### EKF扩展卡尔曼滤波

#### UKF无迹卡尔曼滤波

## 多传感器融合跟踪

## 多模态数据融合